# MongoDB to Oracle ETL Pipeline

MongoDBì—ì„œ Oracle Databaseë¡œ ë°ì´í„°ë¥¼ ì¶”ì¶œ, ë³€í™˜, ì ì¬í•˜ëŠ” ê°•ë ¥í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ETL íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

## ğŸ“‹ ì£¼ìš” íŠ¹ì§•

- **MongoDB Aggregation Pipeline í™œìš©**: íš¨ìœ¨ì ì¸ ë°ì´í„° ì¶”ì¶œ
- **Repository íŒ¨í„´**: ê¹”ë”í•œ ë°ì´í„° ì ‘ê·¼ ê³„ì¸µ
- **ê°•ë ¥í•œ ì—ëŸ¬ ì²˜ë¦¬**: ê³„ì¸µë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
- **Job ê´€ë¦¬ ì‹œìŠ¤í…œ**: MongoDB ê¸°ë°˜ Job ì¶”ì  ë° ëª¨ë‹ˆí„°ë§
- **ë³‘ë ¬ ì²˜ë¦¬**: ThreadPoolExecutorë¥¼ í†µí•œ ê³ ì„±ëŠ¥ ì²˜ë¦¬
- **Airflow í†µí•©**: ìŠ¤ì¼€ì¤„ë§ ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- **í¬ê´„ì ì¸ ë¡œê¹…**: ë‚ ì§œë³„ ë¡œê·¸ íŒŒì¼ ê´€ë¦¬
- **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**: ë†’ì€ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- Python 3.8+
- MongoDB 4.4+
- Oracle Database 12c+
- Oracle Instant Client (cx_Oracleìš©)

### ì„¤ì¹˜

1. ì €ì¥ì†Œ í´ë¡ :
```bash
git clone https://github.com/yourusername/mongo-oracle-etl.git
cd mongo-oracle-etl
```

2. ê°€ìƒ í™˜ê²½ ìƒì„± ë° í™œì„±í™”:
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3. ì˜ì¡´ì„± ì„¤ì¹˜:
```bash
pip install -r requirements.txt
pip install -e .
```

4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:
```bash
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ ì„¤ì •
```

### ì‹¤í–‰

#### ê¸°ë³¸ ì‹¤í–‰
```bash
python scripts/run_etl.py \
    --source-collection sample_collection \
    --mode incremental
```

#### ë‚ ì§œ ë²”ìœ„ ì§€ì •
```bash
python scripts/run_etl.py \
    --source-collection sample_collection \
    --mode incremental \
    --date-from 2024-01-01 \
    --date-to 2024-01-31
```

#### Dry Run (ì‹¤ì œ ì ì¬ ì—†ì´ í…ŒìŠ¤íŠ¸)
```bash
python scripts/run_etl.py \
    --source-collection sample_collection \
    --mode full \
    --dry-run
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
mongo_oracle_etl/
â”œâ”€â”€ config/                 # ì„¤ì • ê´€ë¦¬
â”‚   â”œâ”€â”€ settings.py        # í™˜ê²½ ì„¤ì •
â”‚   â”œâ”€â”€ database.py        # DB ì—°ê²° ê´€ë¦¬
â”‚   â””â”€â”€ logging_config.py  # ë¡œê¹… ì„¤ì •
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/            # ë°ì´í„° ëª¨ë¸
â”‚   â”œâ”€â”€ repositories/      # Repository íŒ¨í„´ êµ¬í˜„
â”‚   â”œâ”€â”€ transformers/      # ë°ì´í„° ë³€í™˜ ë¡œì§
â”‚   â”œâ”€â”€ etl/              # ETL í•µì‹¬ ë¡œì§
â”‚   â”œâ”€â”€ jobs/             # Job ê´€ë¦¬
â”‚   â”œâ”€â”€ exceptions/       # ì»¤ìŠ¤í…€ ì˜ˆì™¸
â”‚   â””â”€â”€ utils/            # ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ tests/                # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”œâ”€â”€ logs/                 # ë¡œê·¸ íŒŒì¼
â””â”€â”€ scripts/              # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
```

## ğŸ”§ ì„¤ì •

### MongoDB Aggregation Pipeline

Pipelineì„ ë™ì ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from src.etl.extractor import MongoExtractor

extractor = MongoExtractor('collection_name')
pipeline = extractor.build_pipeline(
    match_filter={'status': 'active'},
    project_fields={'name': 1, 'value': 1},
    sort_by={'created_at': -1},
    limit=1000
)
```

### ì»¤ìŠ¤í…€ ë³€í™˜ ê·œì¹™

ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ë§ëŠ” ë³€í™˜ ê·œì¹™ì„ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from src.transformers.data_transformer import DataTransformer

transformer = DataTransformer()

# ë³€í™˜ ê·œì¹™ ë“±ë¡
transformer.register_rule('name', lambda x: x.upper())

# ê²€ì¦ ê·œì¹™ ë“±ë¡
transformer.register_validator('age', lambda x: 0 < x < 120)
```

### Job ì¶”ì 

ëª¨ë“  ETL ì‹¤í–‰ì€ ìë™ìœ¼ë¡œ ì¶”ì ë©ë‹ˆë‹¤:

```python
from src.jobs.job_tracker import JobTracker

tracker = JobTracker()

# ìµœê·¼ Job ì¡°íšŒ
recent_jobs = tracker.get_recent_jobs(
    job_type='etl_sample',
    status='completed',
    limit=10
)

# Job ìƒíƒœ í™•ì¸
job_status = tracker.get_job_status('job_id_123')
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
pytest tests/unit/ -v
```

### í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
pytest tests/integration/ -v
```

### ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸ ìƒì„±
```bash
pytest tests/ --cov=src --cov-report=html
```

## ğŸš Airflow í†µí•©

Airflow DAG ì˜ˆì‹œ:

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import timedelta
from airflow.utils.dates import days_ago

default_args = {
    'owner': 'data-team',
    'retries': 2,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'mongodb_to_oracle_etl',
    default_args=default_args,
    schedule_interval='0 2 * * *',
    start_date=days_ago(1)
)

etl_task = BashOperator(
    task_id='run_etl',
    bash_command='/path/to/scripts/run_etl.sh --mode incremental',
    dag=dag
)
```

## ğŸ³ Docker ì‚¬ìš©

### ê°œë°œ í™˜ê²½ êµ¬ì¶•
```bash
docker-compose up -d
```

### ETL ì‹¤í–‰
```bash
docker-compose run etl-app python scripts/run_etl.py \
    --source-collection sample_collection \
    --mode incremental
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ í™•ì¸
ë¡œê·¸ëŠ” `logs/YYYYMMDD/` ë””ë ‰í† ë¦¬ì— ì¼ë³„ë¡œ ì €ì¥ë©ë‹ˆë‹¤:
```bash
tail -f logs/$(date +%Y%m%d)/etl.log
```

### Job ìƒíƒœ ëª¨ë‹ˆí„°ë§
MongoDBì˜ Job ì»¬ë ‰ì…˜ì„ í†µí•´ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§:
```javascript
// MongoDB Shell
db.etl_jobs.find({
    status: "running"
}).sort({ created_at: -1 })
```

## ğŸ” ë³´ì•ˆ

- í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•œ ë¯¼ê°í•œ ì •ë³´ ê´€ë¦¬
- `.env` íŒŒì¼ì€ ì ˆëŒ€ ì»¤ë°‹í•˜ì§€ ì•ŠìŒ
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì‹œí¬ë¦¿ ê´€ë¦¬ ë„êµ¬ ì‚¬ìš© ê¶Œì¥

## ğŸ¤ ê¸°ì—¬

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Oracle ì—°ê²° ë¬¸ì œ
```bash
# Oracle Instant Client ì„¤ì¹˜ í™•ì¸
python -c "import cx_Oracle; print(cx_Oracle.version)"

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export LD_LIBRARY_PATH=/opt/oracle/instantclient:$LD_LIBRARY_PATH
```

### MongoDB ì—°ê²° íƒ€ì„ì•„ì›ƒ
```python
# config/settings.pyì—ì„œ íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¡°ì •
MONGODB = MongoDBConfig(
    # ...
    connection_timeout=10000,  # 10ì´ˆ
    server_selection_timeout=5000  # 5ì´ˆ
)
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ
```python
# ë°°ì¹˜ í¬ê¸° ì¡°ì •
ETL_BATCH_SIZE=500  # ê¸°ë³¸ê°’ 1000ì—ì„œ ê°ì†Œ
ETL_WORKERS=2  # ë³‘ë ¬ ì›Œì»¤ ìˆ˜ ê°ì†Œ
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### 1. MongoDB ì¸ë±ìŠ¤ ìµœì í™”
```javascript
// ìì£¼ ì‚¬ìš©ë˜ëŠ” í•„ë“œì— ì¸ë±ìŠ¤ ìƒì„±
db.collection.createIndex({ "created_at": 1, "status": 1 })
db.collection.createIndex({ "_id": 1, "processed": 1 })
```

### 2. Oracle ë²Œí¬ ì‘ì—…
```python
# ë‹¨ì¼ ì‚½ì… ëŒ€ì‹  ë²Œí¬ ì‚½ì… ì‚¬ìš©
loader.load_batch(records, batch_size=1000)
```

### 3. ë³‘ë ¬ ì²˜ë¦¬ íŠœë‹
```python
# CPU ì½”ì–´ ìˆ˜ì— ë”°ë¼ ì›Œì»¤ ìˆ˜ ì¡°ì •
import multiprocessing
ETL_WORKERS = multiprocessing.cpu_count()
```

## ğŸ¯ ì‚¬ìš© ì‚¬ë¡€

### 1. ì¼ì¼ ì¦ë¶„ ETL
```bash
# Crontab ì„¤ì •
0 2 * * * cd /path/to/project && ./scripts/run_etl.sh --mode incremental
```

### 2. ì „ì²´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
```bash
python scripts/run_etl.py \
    --source-collection all_data \
    --mode full \
    --batch-size 5000
```

### 3. íŠ¹ì • ì¡°ê±´ ë°ì´í„° ì²˜ë¦¬
```python
# ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ìƒì„±
pipeline = [
    {'$match': {
        'category': 'premium',
        'value': {'$gte': 1000}
    }},
    {'$lookup': {
        'from': 'users',
        'localField': 'user_id',
        'foreignField': '_id',
        'as': 'user_info'
    }}
]
```

## ğŸ”„ ì—…ë°ì´íŠ¸ ë‚´ì—­

### v1.0.0 (2024-01-15)
- ì´ˆê¸° ë¦´ë¦¬ìŠ¤
- MongoDBì—ì„œ Oracleë¡œì˜ ê¸°ë³¸ ETL ê¸°ëŠ¥
- Job ì¶”ì  ì‹œìŠ¤í…œ
- Airflow í†µí•©

### ê³„íšëœ ê¸°ëŠ¥
- [ ] ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ETL (Change Streams)
- [ ] ì›¹ ê¸°ë°˜ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- [ ] ë” ë§ì€ ë°ì´í„° ì†ŒìŠ¤ ì§€ì› (PostgreSQL, MySQL)
- [ ] ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í”„ë ˆì„ì›Œí¬
- [ ] ìë™ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜

## ğŸ“ ì§€ì›

- ì´ìŠˆ ë¦¬í¬íŠ¸: [GitHub Issues](https://github.com/yourusername/mongo-oracle-etl/issues)
- ì´ë©”ì¼: support@example.com
- ë¬¸ì„œ: [Wiki](https://github.com/yourusername/mongo-oracle-etl/wiki)

## ğŸ‘¥ íŒ€

- í”„ë¡œì íŠ¸ ë¦¬ë“œ: Your Name
- ê°œë°œíŒ€: Data Engineering Team

---

**Note**: ì´ í”„ë¡œì íŠ¸ëŠ” ì§€ì†ì ìœ¼ë¡œ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. í”¼ë“œë°±ê³¼ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!